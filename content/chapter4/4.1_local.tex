\subsection{Local experiments}
\label{sec:runtime_local}

Table~\ref{tab:local_runtimes} shows the runtimes of each dataset at different scales.
The scaling factors were increased until the distributed started outperforming the local execution.
It can be observed that at small scales execution time is near constant, this can be seen for all datasets up to scaling factor 8 except \textit{tax}, that is the largest dataset and contains all types of errors.
Once trivial sizes are exceeded, doubling data size leads to more than doubled execution time.
This indicates super linear scaling of the data generation and validation.
It is assumed that the performance of the framework should be linear, but, according to the measured times, this is not the case for the error generation part of the framework.
None of the operations used indicate super linear execution time, but a hypothesis could be that random memory access leads to frequent cache misses and cache evictions.
% TODO data sizes 

\begin{table}[!t]
\caption{\label{tab:local_runtimes}Local runtimes [S] with different scales}
\centering
\begin{tabular}{r|K|K|K|K|K|K}
\toprule
\textbf{Scale} & \colCenter{beers} & \colCenter{flights} & \colCenter{hospital} & \colCenter{movies} & \colCenter{rayyan} & \colCenterNoRight{tax} \\ \midrule
 2  &  2.0 &   2.7 &  2.0 &   5.0 &   1.9 &    25.0 \\
 4  &  2.2 &   3.1 &  2.1 &   5.4 &   2.1 &    42.8 \\
 8  &  1.8 &   3.4 &  2.3 &   6.6 &   2.3 &   100.6 \\
16  &  3.0 &   5.1 &  2.6 &   9.4 &   3.3 &   325.6 \\
32  &  3.8 &   9.1 &  3.4 &  16.5 &   5.6 &  1228.1 \\
64  &  5.6 &  26.2 &  4.9 &  43.1 &  13.3 &  5192.6 \\
128 &  8.8 &  98.1 &  7.5 & 151.5 &  44.9 & 21380.5 \\
256 & 17.3 & 390.7 & 13.4 & 581.0 & 176.0 & --- \\
\bottomrule
\end{tabular}
\end{table}
