% Checked with grammarly
\section{Types of Errors}
\label{sec:error_types}

Data errors are values that differ from the ground truth.
In this context, we differentiate between data with and without errors by calling it clean or dirty. 
Completely clean data is ground truth (GT).  


In the context of this benchmark, we have a clean ground-truth dataset and a dirty version with introduced errors.  
Leveraging this, faulty values can be found by locating the cells that differ between dirty and clean. 
This information is helpful to detect errors and their distribution, and frequencies of specific values being error prone.  
Moreover, it is useful for classification of error types.


\textbf{Five error types}, that are common in the real-world datasets, are considered in this benchmark: 
Missing values, typos, outliers, replacements and swaps. 
The error types and descriptions are shown in Table~\ref{tab:generator_errors}.


\textbf{Missing value} is the simplest type of error that is frequently seen in our experimentation. 
Generally, there are three sub categories of missing values: 
Missing Completely at Random (MCAR), Missing at Random (MAR), Missing Not at Random (MNAR). 
MCAR is a value that is missing completely independently from other values. 
Missing values have no dependencies or ties to any other values in the dataset. 
MAR occurs when the missing value is random, but is related to the part of the observed data, an instance of this is where in datasets with personal weight, females are less inclined to include their weight. 
MNAR means that the missing value of an observation depends on its values, for instance, using the weight example again, weight is not reported for obese individuals.
MNAR analysis is problematic because the distribution of the missing observations depends on both observed and unobserved values.
Missing data introduce various problems. 
First, the absence of data reduces statistical power of the dirty dataset, moving it's statistical properties further from ground truth.
Second, the lost data can cause bias in the estimation of parameters. The previous example of people not reporting if they are obese could be a cause of this. 
Third, the representativeness of the samples can influence the set of distinct values, frequencies, and ratios between them.


The benchmark supports MCAR and MAR. 
% TODO how we maintain these properties


\textbf{Typo} is a typographical error that typically is introduced by misspelling. 
Common instances of typos are \textsc{Morrocco} and \textsc{Lost Angeles}. 
Introducing typos can violate the set of distinct values, since new distinct values can be inserted.
This can be detrimental for techniques such as one-hot-encoding that is highly sensitive to the number of distinct values.
In the benchmark, the typo distribution and the distinct value set are used to estimate the number of new unique typos to add to the generated output. 
The new distinct typos are generated by modifying existing values. Modifications are controlled by measuring Levenshtein distance between the clean and modified values. 


\textbf{Outlier} is a data point that significantly differs from a data distribution.
An example of this could be human adult height equal to 3m, 20cm, or a negative value such as -1.5m. 
Since outliers increase variability in data, they decrease statistical power.
In our benchmark we are introducing outliers while preserving dirty data statistics. 
New outlier values are created using correction, in Equation~\ref{eq:outlier_correction}. 
Correction is used to shift actual mean of the data to the desired dirty mean. 
To introduce outliers preserving the statistics, every new outlier should be balanced by another outlier. 
% TODO
Thus, we generate outlier value and it is mirroring such that
we need to set up maximal distance to we reflect upper and lower limits that define outliers  
\begin{equation}
\label{eq:outlier_correction}
\textsc{correction} = \frac{(\textsc{mean\_dirty} - \textsc{mean\_generated}) \cdot \textsc{nrow\_generated})}{\textsc{num\_outliers}}
\end{equation}
% TODO other explanation how we limit outlier with correction

% # Recompute limits for later balancing: max distance to mean, holds for both sides
%         dist_from_mean_to_outliers = max(abs(upper_limit - err_dist.dirty_mean[col_name]), abs(err_dist.dirty_mean[col_name] - lower_limit))
%         lower_limit, upper_limit = err_dist.clean_mean[col_name] - dist_from_mean_to_outliers, err_dist.clean_mean[col_name] + dist_from_mean_to_outliers

%         # Reflect around zero and subtract correction
%         distance_to_zero = max(abs(lower_limit), abs(upper_limit))
%         lower_limit, upper_limit = (-1 * distance_to_zero) - correction, distance_to_zero - correction

\textbf{Replacement} is a flipped value that was chosen from the existing set of valid values. 
For example, in feature with distinct set of values \textsc{\{A, B, C\}}, \textsc{A} can be replaced by \textsc{D}. 
Replacement does not introduce new distinct values, but change the frequencies of the different distinct values. 
This reduces statistical power of the dirty dataset, moving it's statistical properties further from ground truth.
In the benchmark, to preserve statistical properties, pairs of correspondences of replacements are detected and scaled randomly. 

\textbf{Swap} is a pair of values swapped between two columns: numerical and categorical, categorical and categorical or two categorical.
% TODO




The focus is on a single source datasets, thus multiple data source datasets and errors that occur during schema integration are not considered.


Data errors can be categorized by levels of their appearance in the data: single value, within a single feature, within a single tuple, within several features or tuples.

% TODO bias
% TODO in-estimation

% Our error generation includes properties such as:
% \begin{itemize}
%     \item Error type: A variety of different error types can be introduced to the data.
%     \item Error rate: A configurable for each error rate, that specifies am amount of occurances of respective error.
%     \item Reproducibility: Each and every introduced error can be reproduced and tracked.
% \end{itemize}


% \begin{table}[!h]
% \caption{\label{tab:generator_errors}Errors preserved by generator}
% \begin{tabular}{l|l|l}
% \toprule
% Error name    & Parameters                                                                                                             & Description                                                                           \\ 
% \midrule
% Missing value & \begin{tabular}[c]{@{}l@{}}text text text text text text \\ text text text text text text\end{tabular} & \begin{tabular}[c]{@{}l@{}}text text text text text text \\ text text text text text text\end{tabular} \\
% Typo          &\begin{tabular}[c]{@{}l@{}}text text text text text text \\ text text text text text text\end{tabular} & \begin{tabular}[c]{@{}l@{}}text text text text text text \\ text text text text text text\end{tabular} \\
% Outlier       &\begin{tabular}[c]{@{}l@{}}text text text text text text \\ text text text text text text\end{tabular} & \begin{tabular}[c]{@{}l@{}}text text text text text text \\ text text text text text text\end{tabular} \\
% Replacement   &\begin{tabular}[c]{@{}l@{}}text text text text text text \\ text text text text text text\end{tabular} & \begin{tabular}[c]{@{}l@{}}text text text text text text \\ text text text text text text\end{tabular} \\
% Swap          &\begin{tabular}[c]{@{}l@{}}text text text text text text \\ text text text text text text\end{tabular} & \begin{tabular}[c]{@{}l@{}}text text text text text text \\ text text text text text text\end{tabular} \\
% \bottomrule
% \end{tabular}
% \end{table}