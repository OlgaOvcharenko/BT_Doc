% Checked with grammarly
\section{Types of Errors}
\label{sec:error_types}

Data errors are values that differ from the ground truth.
In this context, we differentiate between data with and without errors by calling it clean and dirty. 
Completely clean data is ground truth (GT).  
In the context of this benchmark, we have a clean ground-truth dataset and its dirty version with earlier introduced errors.  
Leveraging this, faulty values can be found by locating the cells that differ between dirty and clean. 
This information is helpful to detect errors, their distribution, and frequencies of specific values being error prone.  
Moreover, it is useful for classification of error types.

\textbf{The five error types} chosen are common in the real-world datasets. They include missing values, typos, outliers, replacements and swaps. 

\textbf{Missing values:} 
The simplest type of error that is frequently seen in our experimentation is missing value. 
Generally, there are three sub categories of missing values: 
Missing Completely at Random (MCAR), Missing at Random (MAR), Missing Not at Random (MNAR). 
MCAR is a value that is missing completely independently from other values. 
Missing values have no dependencies or ties to any other values in the dataset. 
MAR occurs when the missing value is random, but is related to the part of the observed data, an instance of this is where in datasets with personal weight, females are less inclined to include their weight. 
MNAR means that the missing value of an observation depends on its values, for instance, using the weight example again, weight is not reported for obese individuals.
MNAR analysis is problematic because the distribution of the missing observations depends on both observed and unobserved values.
Missing data introduce various problems. 
First, the absence of data reduces statistical power of the dirty dataset, moving it's statistical properties further from ground truth.
Second, lost data can cause bias in the estimation of parameters. The previous example of people not reporting if they are obese could be a cause of this. 
Third, the representativeness of the samples can influence the set of distinct values, frequencies, and ratios between them.
The benchmark supports MCAR. 
New missing values are generated using unique missing values of the original dirty dataset. 
To maintain the frequencies of values, existing missing values are scaled up, and number of new missing values is estimated by Schlosser \cite{HassNSS1995} and Hasso Stokes \cite{HassS1998} estimation algorithms.

\textbf{Typos:} 
Typo is a typographical error that typically is introduced by misspelling. 
Common instances of typos are \textsc{Morrocco} and \textsc{Lost Angeles}. 
Introduction of typos can violate the set of distinct values, since new distinct values can be inserted.
This can be detrimental for techniques such as one-hot-encoding that is highly sensitive to the number of distinct values.
In the benchmark, the typo distribution and the distinct value set are used to estimate the number of new unique typos to add to the generated output. 
The new distinct typos are generated by modifying existing values multiple times.
Following modifications are randomly performed: add existing character, add new character, remove existing character, and swap two existing characters.
Modifications are controlled by measuring Levenshtein distance between the clean and modified values. 

\textbf{Outliers:} 
A data point that significantly differs from a data distribution is called an outlier.
An example of this could be human adult height equal to 3m, 20cm, or a negative value such as -1.5m. 
Since outliers increase variability in data, they decrease statistical power.
In our benchmark we are introducing outliers while preserving dirty data statistics. 
New outlier values are created using the correction, in Equation~\ref{eq:outlier_correction}. 
Correction is used to shift actual mean of the scaled data to the desired mean of the dirty data.
Correction increases interquartile range.
To introduce outliers preserving the statistics, every new outlier should be balanced by another outlier. Thus, outliers are created in pairs of values that balance the outliers. 
In essence the balanced outlier values utilize the concept of reflection symmetry around mean.  
We generate initial outliers using interquartile range, shifting delimiter, distribution, or minimum and maximum of the clean dataset.
\begin{equation}
\label{eq:outlier_correction}
\textsc{correction} = \frac{(\textsc{mean\_dirty} - \textsc{mean\_generated}) \cdot \textsc{nrow\_generated})}{\textsc{num\_outliers}}
\end{equation}

\textbf{Replacements:} 
Replacement is a flipped value that was chosen from the existing set of valid values. 
For example, in feature with distinct set of values \textsc{\{A, B, C\}}, \textsc{A} can be replaced by \textsc{D}. 
Replacement does not introduce new distinct values, but changes the frequencies of the different distinct values. 
It reduces statistical power of the dirty dataset and moves it's statistical properties further from ground truth.
In the benchmark, correspondence pairs of replacements and their frequencies are detected, and scaled accordingly. 

\textbf{Swaps:} 
An exchange of pair of values within an observation is a swap. 
Mostly, they occur when data is misplaced while entering.
For instance, a \textsc{DoB} value \textsc{01.01.2001} is mistakenly filled into \textsc{Surname}, and \textsc{Surname} value \textsc{Smith} - into \textsc{DoB}.
Swaps introduce new irrelevant distinct items or outliers if two numerical values are swapped.
In the benchmark, swaps are generated based on their distribution in the dirty dataset. Swaps are detected and counted, then the number of swaps is scaled. This approach allows to maintain data distribution while generating new dataset, without introducing violating distinct value set of the dirty data.

\textbf{Error generation properties:} 
Single source datasets are used to introduce errors. 
Thus, multiple source datasets and errors that occur during schema integration are not considered in the framework.
The error generation includes properties such as error distribution and reproducibility. Respective errors are introduced to the scaled dataset according to the dirty data error distribution. The whole data generation is seeded, and errors origin can be tracked.


\textbf{Biasness of introduced errors:} 
Bias in the data generation is unavoidable, especially under the constraints of preserving data distribution, statistics, and error fractions. 
Missing values are introduced at random. This leads to potential replacing of never missing values in original data.
Moreover, for small scales (e.g., 2x) this random application can effect statistics significantly, such as mean.
Typos are generated by modification of existing distinct values, thus fully new relevant typos can not be guaranteed.
Outliers are biased by the statistics that the introduction of outliers tries to fix.
Additionally, similar to missing values, outliers are introduced at random.
Replacements and swaps are not biased and reproduce the original dirty data via the counts of the specific swaps/replacements of 'a' and 'b'.
Both these types do not introduce new values and only modify existing dirty-clean pairs seen in the original dataset.
