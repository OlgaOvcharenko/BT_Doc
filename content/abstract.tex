\chapter*{Abstract}

% State the problem
Data preparation is a crucial part of the data science lifecycle.
Most state-of-the-art tools and frameworks contain data cleaning functionality, 
but many of them require manual effort to prepare the input or to define constraints.
There is a lack of large real-world datasets with ground truth that can be used for benchmarking data cleaning frameworks, e.g., for evaluation of results.
The best existing solution is the generation of synthetic data, but it does not represent the real-world problems and errors.
% Say why it is  an interesting problem
It would be interesting and helpful for the community if one could cheaply generate new large datasets from small samples of dirty and clean data.
Since any non-trivial data sizes lead to new challenges in both data cleaning and full ML pipelines.
% Say what your solution achieves (200 words)
Hence, this work focuses on data generation, observations of the original clean and dirty data are used to scale up to arbitrary data sizes.
The biggest scaling factor achieved is \numprint{65536}x, and the largest data size achieved was \numprint{18} GB.
These results were achieved under the constraints of preserving data statistics and the error distribution, and new algorithms were applied.
The generator can run either locally, or distributed via Apache Spark.
As expected, the local execution is faster up to 42x for small scaling factors, 
while, on the other hand, when scaling to larger sizes the distributed execution shows better performance and scalability for data sizes that would not fit in single node memory.  % performs
% Say what follows from your solution (25 words)
% Starting out, i
It was challenging to introduce errors preserving the characteristics of the original dataset, and to scale to arbitrary sizes. 
% since such errors as e.g. outliers change the mean drastically.
The proposed framework solves the problem of the large-scale data generation, and provides data generation for benchmarking cleaning for ML tools.
% cleaning for ML benchmarks by scaling data and its distribution.

% The proposed framework solves problem of the large-scale data generation, and provides a solution for cleaning for ML benchmarks by scaling data and its distribution.

% 261 words
\newpage\null\thispagestyle{empty}\newpage
